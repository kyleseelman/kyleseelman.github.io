<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Kyle Seelman | AI Researcher</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
  <header class="bg-white shadow p-6">
    <div class="max-w-5xl mx-auto flex justify-between items-center">
      <div class="flex items-center space-x-4">
        <img src="/headshot.jpg" alt="Kyle Seelman" class="w-16 h-16 rounded-full object-cover">
        <h1 class="text-3xl font-bold">Kyle Seelman</h1>
      </div>
      <nav class="space-x-6">
        <a href="#about" class="hover:underline">About</a>
        <a href="#research" class="hover:underline">Research</a>
        <a href="#projects" class="hover:underline">Projects</a>
        <a href="#skills" class="hover:underline">Skills</a>
        <a href="/Kyle_Seelman_CV.pdf" class="text-blue-600 font-medium">CV</a>
      </nav>
    </div>
  </header>

  <main class="max-w-5xl mx-auto p-6 space-y-16">
    <!-- About -->
    <section id="about">
      <h2 class="text-2xl font-bold mb-2">About</h2>
      <p class="text-lg">
        I'm a PhD candidate in Computer Science at the University of Maryland, advised by Jordan Boyd-Graber and Hal Daumé III. 
        My research focuses on interactive and human-in-the-loop NLP, large language models, and explainable AI. I have experience leading teams, fine-tuning LLMs, and building full-stack AI systems. 
        I enjoy bridging the gap between academic research and real-world deployment.
      </p>
      <div class="mt-4">
        <a href="mailto:kseelman@umd.edu" class="text-blue-500">kseelman@umd.edu</a> | 
        <a href="https://github.com/YOUR_USERNAME" class="text-blue-500">GitHub</a> | 
        <a href="https://linkedin.com/in/YOUR_USERNAME" class="text-blue-500">LinkedIn</a>
      </div>
    </section>

    <!-- Research -->
    <section id="research">
      <h2 class="text-2xl font-bold mb-2">Research & Publications</h2>
      <ul class="list-disc list-inside space-y-2">
        <li><strong>Archivist: Incorporating the World Knowledge of Neural Language Models into Topic Models as a Bayesian Prior</strong> <b>Kyle Seelman</b>, Jordan Boyd-Graber (EMNLP 2025, submitted)</li>
        <li><strong>From Text to Traits: Zero-shot Personality Facet Prediction with Open-source Language Models</strong> <b>Kyle Seelman</b>, Anton Rytting, Triet Lee, Jordan Boyd-Graber (CoNLL 2025, submitted)</li>
        <li><strong>Labeled Interactive Neural Topic Models: No Longer Take It or Leave It</strong> <b>Kyle Seelman</b>, Mozhi Zhang, Jordan Boyd-Graber (ACL 2025, submitted)</li>
        <li><strong>Decoding Digital Discourse: An Observational Study using Multimodal Text and Image Machine Learning Models to Classify Sentiment, Hate, and Anti-Hate</strong> Thu T. Nguyen, Xiaohe Yue, Heran Mane, <b>Kyle Seelman</b>, Penchala Sai Priya Mullaputi, Elizabeth Dennard, Amrutha Alibilli, Junaid S. Merchant, Shaniece Criss, Yulin Hswen, Quynh C. Nguyen (JIMR 2025)</li>
        <li><strong>What’s Different between Visual Question Answering for Machine ``Understanding'' Versus for Accessibility?</strong> Yang Trista Cao*, <b>Kyle Seelman*</b>, Kyungjun Lee*, Hal Daumé III Best Theme Paper, AACL-IJCNLP 2022</li>
      </ul>
    </section>

    <!-- Projects -->
    <section id="projects">
      <h2 class="text-2xl font-bold mb-2">Projects</h2>
      <div class="space-y-4">
        <div>
          <h3 class="font-semibold">Interactive Topic Modeling Tool</h3>
          <p>Developed an NLP interface for user-guided document exploration using human-in-the-loop topic models; deployed and evaluated through user studies and BM25 metrics.</p>
        </div>
        <div>
          <h3 class="font-semibold">LLM Personality Predictor</h3>
          <p>Built zero-shot and few-shot personality trait predictors using LLMs and evaluated across social media datasets.</p>
        </div>
        <div>
          <h3 class="font-semibold">Visual Question Answering for Accessibility</h3>
          <p>Created a VQA pipeline using CLIP and VisualBERT tailored to improve screen reader experiences for visually impaired users.</p>
        </div>
      </div>
    </section>

    <!-- Skills -->
    <section id="skills">
      <h2 class="text-2xl font-bold mb-2">Technical Skills</h2>
      <ul class="grid grid-cols-2 gap-4 list-disc list-inside">
        <li>Python, Java, C++, SQL, JavaScript</li>
        <li>PyTorch, TensorFlow, Hugging Face, LangChain</li>
        <li>LLM Fine-tuning, Prompt Engineering, RAG</li>
        <li>Docker, Git, AWS, REST APIs</li>
        <li>Full-stack Dev, MVP Prototyping</li>
        <li>Human-in-the-loop Systems, Evaluation Frameworks</li>
      </ul>
    </section>
  </main>

  <footer class="text-center text-sm text-gray-500 p-4">
    &copy; 2025 Kyle Seelman
  </footer>
</body>
</html>
